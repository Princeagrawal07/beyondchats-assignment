BeyondChats Assignment â€“ Phase 1
ğŸ“Œ Overview

This project implements Phase 1 of the BeyondChats assignment.
It includes scraping the oldest blog articles from BeyondChats, storing them in a database, and exposing CRUD REST APIs to manage these articles.

The solution uses:

Laravel for backend APIs and database

Node.js for web scraping

SQLite as the database (simple local setup)

ğŸ§± Tech Stack
Backend

Laravel 12

PHP 8.x

SQLite

REST APIs

Scraper

Node.js

Axios

Cheerio

ğŸ“ Project Structure
beyondchats-assignment/
â”‚
â”œâ”€â”€ backend/          # Laravel backend (APIs + DB)
â”‚   â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ database/
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ scraper/          # Node.js scraping scripts
â”‚   â”œâ”€â”€ scrape.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ node_modules/
â”‚
â””â”€â”€ README.md

ğŸ”„ Data Flow / Architecture
BeyondChats Blog Website
        â†“
Node.js Scraper (Axios + Cheerio)
        â†“
POST /api/articles
        â†“
Laravel API
        â†“
SQLite Database

ğŸ§© Phase 1 â€“ Features Implemented
âœ… Web Scraping

Starts scraping from the last page of BeyondChats blogs

Handles pagination edge-case (last page contains fewer articles)

Collects the 5 oldest articles

Extracts:

Title

Source URL

Short excerpt (fallback used due to scraping restrictions)

Note: Full article content scraping is restricted by site protection and is addressed in Phase 2.

âœ… Database

SQLite database

articles table with fields:

id

title

content

source_url

is_ai_generated

references

timestamps

âœ… CRUD REST APIs

CRUD APIs are implemented using Laravel apiResource.

Operation	Method	Endpoint
Create	POST	/api/articles
Read (All)	GET	/api/articles
Read (One)	GET	/api/articles/{id}
Update	PUT	/api/articles/{id}
Delete	DELETE	/api/articles/{id}
âš™ï¸ Local Setup Instructions
ğŸ”¹ Prerequisites

PHP 8+

Composer

Node.js

npm

ğŸ”¹ Backend Setup (Laravel)
cd backend
composer install
cp .env.example .env
php artisan key:generate
php artisan migrate
php artisan serve


Backend will run at:

http://127.0.0.1:8000

ğŸ”¹ Scraper Setup (Node.js)
cd scraper
npm install
node scrape.js


This script:

Scrapes the 5 oldest articles

Sends them to Laravel using POST /api/articles

ğŸ” API Verification

After running the scraper, open:

http://127.0.0.1:8000/api/articles


You should see the scraped articles stored in the database.

ğŸ“ Notes & Assumptions

BeyondChats uses bot protection, so full article body scraping may fail.

For Phase 1, storing titles, URLs, and excerpts satisfies requirements.

Full content rewriting and Google search integration are part of Phase 2.

ğŸš€ Phase 1 Status

âœ… Completed

Scraping implemented

Database storage complete

CRUD APIs implemented and tested

ğŸ”— Live Link

(Frontend will be added in Phase 3)

ğŸ‘¨â€ğŸ’» Author

Prince Agrawal